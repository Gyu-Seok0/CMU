{"cells":[{"cell_type":"markdown","metadata":{"id":"So5gjMeClYr7"},"source":["# **HW9: Paragraph Segmentation**\n","\n","Welcome to the final homework of the semester! We introduce the task of Paragraph Segmentation, where given several sentences of documents, our goal is to predict if a sentence marks the beginning of a new paragraph or not in the document. \n","\n","Our aim is to help you better understand the importance of feature extraction and how to curate linguistic features yourselves in training NLP models. We suggest a few methods for you to implement (Part 1), and ask you later to improve upon them using your own ideas (Part 2).\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AfaC-afLg7tL"},"source":["# **Part 1** (70 points)"]},{"cell_type":"markdown","metadata":{"id":"Y_0orf9yqVDg"},"source":["###**Dataset**\n","You will be provided with a dataset called '*Paraseg*' consisting of sentences from different documents, divided into train, dev and test sets. Each sentence is followed by a tab and a label either 'B', or 'I'. A new line denotes the end of a document.\n","\n","'B' means that the current sentence is the beginning of a new paragraph, and in all other cases, the label is 'I'."]},{"cell_type":"markdown","metadata":{"id":"VuC1FLKLsCsD"},"source":["\n","Note: One assumption we make in model training is we treat each sentence separately and not belonging to any particular document. Maybe you can improve upon this later?\n","\n","First things first, let's mount the dataset to Google Drive. You may upload the handout folder 'HW9' to the drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26268,"status":"ok","timestamp":1670701928265,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"jMg3GmJy1bFW","outputId":"65ecdbd6-6ed5-4097-8c21-de5d30deb2bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":530,"status":"ok","timestamp":1670701931139,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"R_Wtk4F_4K7M"},"outputs":[],"source":["origin_path = \"/content/drive/MyDrive/Colab Notebooks/NLP HW9/paraseg/\"\n","\n","train_path = origin_path + \"train/paraseg.train\" # set path to train file  \"/content/drive/MyDrive/HW9/paraseg/train/paraseg.train\" \n","dev_path =  origin_path + \"dev/paraseg.dev\" # set path to dev file  \"/content/drive/MyDrive/HW9/paraseg/dev/paraseg.dev\"\n","test_path = origin_path + \"test/paraseg.test\" # set path to test file \"/content/drive/MyDrive/HW9/paraseg/test/paraseg.test\" "]},{"cell_type":"markdown","metadata":{"id":"xOxubPMisaWC"},"source":["As in previous assignments, we'll be working with PyTorch"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4487,"status":"ok","timestamp":1670701938053,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"0TDHg804n-Su","outputId":"1248b14e-33cc-4497-bf16-3c112b434d5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[K     |████████████████████████████████| 512 kB 24.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: torch\u003e=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n","Requirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging-\u003etorchmetrics) (3.0.9)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.0\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3486,"status":"ok","timestamp":1670701941536,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"KeIApksYoBx6"},"outputs":[],"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_sequence\n","\n","import torchmetrics\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"LEuTXgbrshXJ"},"source":["Please ensure you run on GPU"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1670701941537,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"qUVQTYREmPMe","outputId":"43c35f38-a19c-4a27-eb6b-1c4fd9c6389d"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"markdown","metadata":{"id":"cWoKY0ifDrDU"},"source":["## **Data Preprocessing and Word Embeddings**\n","Our first goal is to preprocess the data. Furthermore, we want to obtain embeddings for each sentence. \n","\n","In order to do that, we use a simple technique of mapping each word to an index. Using an Embedding layer, we can obtain a feature embedding of each word in a sentence. This was very similar to what you did in the previous homeworks, so we won't ask you to implement this again. \n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670701943923,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"34l-aPjMlPoB"},"outputs":[],"source":["OOV_token = 0  # We consider out-of-vocabulary tokens (OOV)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":344,"status":"ok","timestamp":1670701951639,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"PEPc-ki5B1A9"},"outputs":[],"source":["class WordToIndex:\n","    def __init__(self):\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"OOV\"} \n","        self.n_words = 1 \n","        self.n_sentences = 0\n","\n","    def addSentence(self, sentence):\n","        self.n_sentences += 1\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    def indexesFromSentence(self, sentence):\n","        return [self.word2index.get(word, OOV_token) for word in sentence.split(' ')]\n","\n","    def tensorFromSentence(self, sentence):\n","        indexes = self.indexesFromSentence(sentence)\n","        indexes = torch.tensor(indexes, dtype=torch.long)\n","        return indexes"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":953,"status":"ok","timestamp":1670701954016,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"9fzoCdRj6AaQ","outputId":"ef670323-95af-428e-c833-8444ecdb36fd"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["# common words such as 'the', 'a', 'an', etc. are called stopwords\n","# our objective is to remove them since they contribute less to model prediction\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":514,"status":"ok","timestamp":1670701964508,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"-5MD0ZQB4udg"},"outputs":[],"source":["def prepareData(path, word_to_index, train):\n","    f = open(path, 'r') \n","    docs = []\n","    doc = []\n","    x = f.readlines()\n","    for row in x:\n","        if row == '\\n':\n","            docs.append(doc)\n","            doc = []\n","            if(len(docs)) == 1000 and train==False:\n","                break   # We consider only 1000 documents for dev, test for resource purposes\n","            if(len(docs)) == 5000: #We consider only 5000 documents for training for resource purposes\n","                break\n","        else:\n","            [sentence, label] = row.split('\\t')\n","            sentence = re.sub(r'[^\\w\\s]', '', sentence.lower())  #lower case and remove punctuations\n","            filtered_words = [word for word in sentence.split() if word not in stopwords.words('english')]\n","            sentence = \" \".join(filtered_words)\n","\n","            doc.append((sentence.strip(),label.strip()))\n","            if train:\n","                word_to_index.addSentence(sentence)\n","    return docs"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":715209,"status":"ok","timestamp":1670702680759,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"rt-6Ja1nIxjm"},"outputs":[],"source":["#  word_to_index will help you convert each sentence to a tensor of word indices\n","# [train/dev/test]_docs is a list of documents. Each document in turn is a list of (sentence, label) tuples\n","word_to_index = WordToIndex()\n","train_docs = prepareData(train_path, word_to_index, train = True)\n","dev_docs = prepareData(dev_path, word_to_index, train = False)\n","test_docs = prepareData(test_path, word_to_index, train = False)"]},{"cell_type":"markdown","metadata":{"id":"5d5NulBkL714"},"source":["While you wait for the code to prepare the data (and this may time around 10-12 minutes), let's think about this task for a bit. \n","\n","We are finding word embeddings for each sentence for now. But later, we want to define an **embedding for an entire sentence** to help us predict its label. If we have word embeddings for each word in a sentence, what ways can we use it to get an entire sentence embedding? "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1DidHyIJtFzx0xFQFXfVCTZeh61LQMKtY"},"executionInfo":{"elapsed":17010,"status":"ok","timestamp":1670703104207,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"OzD2rkIpqfE_","outputId":"870562a2-0558-4229-b683-c4d46a827767"},"outputs":[],"source":["test_docs"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3053,"status":"aborted","timestamp":1670701641040,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"5u52G6fgVl5L"},"outputs":[],"source":["# define the number of features you want for word embeddings and define an embedding layer. \n","num_embeddings = 50 #you may want to play around with this number and note how it affects model performance\n","embed_layer = nn.Embedding(word_to_index.n_words, num_embeddings) # embedding layer, input is vocabulary size and output is embedding size"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1670701641227,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"ZfygweMJNKsO"},"outputs":[],"source":["# this cell is for your understanding of how to obtain a sentence embedding\n","sentence_word_indices = word_to_index.tensorFromSentence(\"hello this just for testing\")\n","sentence_word_embedding = embed_layer(sentence_word_indices) # embed each word\n","\n","print(sentence_word_embedding.shape) # (num_words, embedding_size)\n","sentence_embedding = sentence_word_embedding.flatten() # flatten each word embedding to obtain a sentence embedding\n","print(sentence_embedding.shape) # we now have a 1d tensor representing each sentence.\n","\n","#will flattening work for sentences of different lengths? may need to pad\n","#other ways to obtain a sentence embedding could be averaging or summing up each word embedding"]},{"cell_type":"markdown","metadata":{"id":"LRPjHICtJhLw"},"source":["## **Feature Extraction**\n","\n","We see a simple way to obtain a sentence embedding of an entire sentence using its word embeddings. We can simply pass these embeddings to our training model to obtain a prediction: 1 (indicating para break 'B') or 0 (otherwise)\n","\n","However, as always, we can do better. We can capture better features from the sentences and use that to predict our labels. The next sections describe few methods to extract such linguistic features, and your task will be to implement them\n"]},{"cell_type":"markdown","metadata":{"id":"6iV5RomDQVWO"},"source":["###1. Discourse Markers (10 points)\n","\n","Words such as 'however', 'although', 'because', etc. can be good indicators of a sentence at the beginning of a paragraph. \n","\n","We ask you to curate a list of such words. Say your list was ['word1', 'word2'] then the presence/absence of word1 in the sentence: \"word1 repeats word1 times not word2\" can result in a one-hot-encoded vector [1, 0]\n","\n","You may also choose to instead store the count of the words as a vector, in this case [2,0]\n","\n","This embedding may later be concatenated with the sentence embedding to provide more information about the label"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1670701641227,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"BJfgGnVkLhnS"},"outputs":[],"source":["discourse_list = #TODO: define discourse list []"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1670701641228,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"aFG9eyuqS5Mr"},"outputs":[],"source":["# sentence is a string, discourse_list is a list of strings\n","def discourse_markers(sentence, discourse_list):\n","    in_features = # TODO: this should be the length of the discourse list \n","    out_features = # TODO: define number of output features\n","    markers = #TODO: initialize as list of 0s of size input_features\n","\n","    sentence = sentence.split()\n","    for word in sentence:\n","        for j, marker in enumerate(discourse_list):\n","            if word == marker:\n","                #TODO: store presence or absence of word or its count in sentence\n","\n","    markers = # TODO: convert list to a tensor\n","    return markers"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1670701641228,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"7EtNkVHaxkOc"},"outputs":[],"source":["markers = discourse_markers(\"however i have to also say however again\", [\"however\", \"but\", \"also\"]).tolist()\n","assert markers == [1,0,1] or markers == [2,0,1]"]},{"cell_type":"markdown","metadata":{"id":"WPJbDd9Dayri"},"source":["###2. Cosine Similarity (10 points)\n","\n","If a sentence is different, in context, from its previous sentence then there is a high chance of it being the beginning of a new paragraph. \n","\n","We can leverage this idea to compute the cosine similarity between the sentence embedding of the current sentence with its previous (or previous two sentences?, up to you). There are probably much better ways to capture this idea, but we stick with a simple implementation. "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1670701641228,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"t8zmQUnQSaEG"},"outputs":[],"source":["cos = # define torch cosine similarity function, be sure to define dim as 0\n","\n","def cosine_sim(sentence_1_embed, sentence_2_embed): # sentence_1 and sentence_2 are embeddings of shape (embedding_size)\n","    cos_sim = # TODO: find cosine similarity between two input sentences\n","    #print the shape of this tensor. Since this is just one item, we may need to reshape this tensor\n","\n","    cos_sim = #TODO: reshape the tensor to size 1\n","    return cos_sim"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1670701641229,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"f61RbqeCS3Rv"},"outputs":[],"source":["s1 = embed_layer(word_to_index.tensorFromSentence(\"hey are you watching the soccer world cup\")).flatten()\n","s2 = embed_layer(word_to_index.tensorFromSentence(\"say soccer one more time i dare you\")).flatten()\n","\n","cos_sim = cosine_sim(s1, s2)\n","assert cos_sim.shape == torch.Size([1])\n","\n","cos_sim = cosine_sim(torch.Tensor([0.2147, -1.911, 3.456]), torch.Tensor([0.4444, -0.6782, 1.121]))\n","assert round(cos_sim.item(), 4) == 0.9623"]},{"cell_type":"markdown","metadata":{"id":"RcPazaLKdwWn"},"source":["### 3. Co-reference Chains (20 points)\n","\n","Co-reference resolution refers to the task of identifying words/phrases which refer to the same entity. We can use this important feature in our task. \n","\n","Say we are currently trying to predict the label for sentence *s{i}* , we can look at a window of previous sentences say *s{i-2}, s{i-1}* and the next sentences *s{i+1}, s{i+2}*. If a coreference exists between any one of the previous sentences *s{i-2}* or  *s{i-1}* and the current or next sentences *s{i}*, *s{i+1}, or s{i+2}* then we can say that the current sentence *s{i}* should NOT be a new paragraph (since it deals with a topic discussed in the preceding and subsequent sentences)."]},{"cell_type":"markdown","metadata":{"id":"dXvSIGyfUpOe"},"source":["We can use [fastcoref](https://pypi.org/project/fastcoref/) for this. This takes as input a single string and predicts the co-reference clusters in them. Please refer to the documentation carefully.\n","\n","Using the function get_clusters() we can obtain the different clusters."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3226,"status":"aborted","timestamp":1670701641229,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"aET_KaUoNxmn"},"outputs":[],"source":["!pip install fastcoref"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3224,"status":"aborted","timestamp":1670701641229,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"ndVoUMLMNx0B"},"outputs":[],"source":["from fastcoref import FCoref\n","coref_model = FCoref(device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":3223,"status":"aborted","timestamp":1670701641230,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"4uy2JJ08RRuW"},"outputs":[],"source":["def get_clusters(combined_sent): #combined sent is a string, consisting of the previous, current and next sentences\n","    preds = #TODO: call predict function of coref_model and pass the sentence as specified in the documentation (list of a single concatenated sentence)\n","    clusters = #TODO: obtain the coref cluster indices (Note: these indices are character indices)\n","    return clusters"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3221,"status":"aborted","timestamp":1670701641230,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"2KBsoUUPrMnf"},"outputs":[],"source":["def num_corefs(prev_sentences, cur_sentence, next_sentences):\n","    combined_sent = \"\"\n","    len_prev_sentences = # you may use this variable to check if a point in a cluster belongs in the prev_sentences or not\n","\n","    # TODO: combine the previous, current and next sentences and store as a single string 'combined_sent'\n","    \n","    clusters = #TODO: obtain clusers from the combined sentence\n","\n","    count = 0\n","\n","    #TODO: based on the clusters, count the number of coreferences that exist from previous sentences to current OR the next sentences\n","    # such a coref will exist if a cluster consists of at least one point from prev_sentences and another point from cur_sentence OR next_sentences\n","\n","    count = #convert to tensor of size 1\n","    return count\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3220,"status":"aborted","timestamp":1670701641231,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"tO7cQ5PnRSAi"},"outputs":[],"source":["sentence1 = 'roger novak and rafa are best friends'\n","sentence2 = 'roger is swiss'\n","sentence3 = 'rafa is left handed'\n","\n","ret = num_corefs([sentence1], sentence2, [sentence3])\n","assert ret.shape == torch.Size([1])\n","assert ret.item() == 2"]},{"cell_type":"markdown","metadata":{"id":"F4k4c9SRGl_g"},"source":["### 4. Lines since last segment (5 points)\n","\n","A very important feature is checking which line number the current sentence is in the current paragraph. If the sentence is the first or second line in a paragraph, then there is low chance of a paragraph break. But if the line was, say, the 10th line in a para, then the intuition is it has a higher chance of being a paragraph segment. \n","\n","You need to make some simple changes in the code below for that. Please refer to variable 'para_len'"]},{"cell_type":"markdown","metadata":{"id":"XniKsMFq1Vu4"},"source":["### Preparing sentence embeddings (10 points)"]},{"cell_type":"markdown","metadata":{"id":"onzihIU8enNP"},"source":["So far, we've processed our data and implemented some feature extraction methods. \n","\n","Now, we tie everything up. We obtain sentence embeddings for each sentence (using word embeddings and the methods describes above). We will then pass these modified and improved sentence embeddings to our training model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3218,"status":"aborted","timestamp":1670701641231,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"d-oZWyGXkwIb"},"outputs":[],"source":["# this function allows us to obtain a sentence embedding from all the word (embeddings)\n","# apart from flattening, you can average or sum out word embeddings\n","\n","def pool_word_embeddings(sent_embedding):\n","    #input dimensions: (num_words, embedding_size)\n","    #output dimensions: (embedding_size)\n","\n","    sent_embedding = #TODO: we expect you to sum each word embedding to obtain a sentence embedding\n","    return sent_embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3217,"status":"aborted","timestamp":1670701641231,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"6vEnrlTdW5Ke"},"outputs":[],"source":["se = torch.tensor([[0.1, 0.2, 0.3], [0.1, 0.2, 0.3]])\n","se = pool_word_embeddings(se)\n","assert torch.equal(se, torch.tensor([0.2,0.4,0.6]))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3216,"status":"aborted","timestamp":1670701641232,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"PEbzwbkufJDW"},"outputs":[],"source":["def get_sentence_embeddings(docs):\n","    sentence_embeddings = []\n","    labels = []\n","    prev = None\n","    para_len = 0    # 4. a very important feature \n","\n","    for i, doc in enumerate(docs):\n","        for j,row in enumerate(doc):\n","            sentence = row[0] \n","            label = #TODO: 'B' indicates 1, otherwise 0\n","            labels.append(label)\n","\n","            if row[1] == 'B':\n","                # set para_len to 0\n","            else:\n","                # increment para_len\n","            \n","            para_len = # TODO: convert to tensor of shape 1\n","\n","            markers = #TODO: obtain discourse markers using the current sentence and the discourse list you defined\n","            \n","            sent_tensor = word_to_index.tensorFromSentence(sentence)\n","            sent_embedding = embed_layer(sent_tensor) \n","\n","            sent_embedding = #TODO: pool word embeddings to obtain sentence embedding\n","\n","            cos_sim = torch.FloatTensor([0])\n","            if prev!=None:\n","                cos_sim = #TODO: find cosine similarity between current and previous sentence\n","            prev = sent_embedding \n","\n","            #uncomment the lines below to calculate number of corefs\n","            # num_coref = torch.FloatTensor([0])\n","            # if j\u003e0 and j\u003clen(doc)-1:\n","            #     prev_sentences = [doc[j-1][0]] \n","            #     next_sentences = [doc[j+1][0]]\n","            #     num_coref = num_corefs(prev_sentences, sentence, next_sentences)\n","\n","            sent_embedding = #TODO: concatenate the sentence embedding with the features obtained from discourse markers, cosine similarity, coreference and para_length\n","            \n","            sentence_embeddings.append(sent_embedding)\n","\n","    sentence_embeddings  = pad_sequence(sentence_embeddings, batch_first=True, padding_value=0) #pad the embeddings\n","    labels = torch.tensor(labels, dtype=torch.float)\n","    return sentence_embeddings, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3214,"status":"aborted","timestamp":1670701641232,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"QWc6ESB1sZ4s"},"outputs":[],"source":["train_sentence_embeddings, train_labels = get_sentence_embeddings(train_docs)\n","train_labels = train_labels.reshape(train_labels.shape[0], 1)\n","print(train_sentence_embeddings.shape)\n","print(train_labels.shape)\n","assert len(train_sentence_embeddings.shape) == 2"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3213,"status":"aborted","timestamp":1670701641233,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"uCQorKxMZkcI"},"outputs":[],"source":["dev_sentence_embeddings, dev_labels = get_sentence_embeddings(dev_docs)\n","test_sentence_embeddings, test_labels = get_sentence_embeddings(test_docs)"]},{"cell_type":"markdown","metadata":{"id":"PTEebVjmjov1"},"source":["### Model Creation and Training (15 points)\n","\n","Great job! We've got some cool sentence embeddings now, which can definitely do a good job at our task of predicting paragraph segmentations. \n","\n","Let us now implement a simple MLP model for our training. We can instead use various sophisticated models like an LSTM too. "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3213,"status":"aborted","timestamp":1670701641234,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"MSC4LSsEfV-O"},"outputs":[],"source":["# you are free to change the architecture of this MLP\n","# you may add more layers to increase complexity, or change the hidden size\n","class MLP(nn.Module):\n","    def __init__(self, input_size, output_size = 1): #output size is 1 for binary classification\n","        super(MLP,self).__init__()\n","        hidden_size = #TODO: define size of hidden layer\n","        self.linear1 = # TODO: define hidden linear layer\n","        self.relu1 = # TODO: define ReLU activation layer\n","        self.linear2 = # TODO: define output layer \n","        self.sigmoid = # TODO: define a sigmoid layer\n","         \n","    def forward(self, input):\n","        # implement the forward function of the MLP\n","        pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":3211,"status":"aborted","timestamp":1670701641234,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"YwUbABlW8k5Q"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-150-9781b75c511f\u003e:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(train_labels[j : j+batch_size])\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0 loss : 0.10408451408147812\n","epoch 1 loss : 0.07082154601812363\n","epoch 2 loss : 0.017085690051317215\n","epoch 3 loss : 0.012588994577527046\n","epoch 4 loss : 0.004164569079875946\n"]}],"source":["# Now we train\n","\n","# we define our optimizer (Adam) and loss function as binary cross entropy loss\n","mlp = #TODO: define training model, input size is the number of features of our modified sentence embeddings\n","learning_rate = # TODO: define a suitable learning rate, we recommend trying out with 1e-5 first\n","optimizer = optim.Adam(mlp.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()\n","mlp = mlp.to(device) #shift model to cuda\n","loss_fn = loss_fn.to(device)\n","\n","num_epochs = 5 # you may experiment with different num_epochs\n","num_sentences = train_sentence_embeddings.shape[0]\n","batch_size = 10 # you may define another batch size\n","mlp.train()\n","\n","for i in range(num_epochs):\n","    for j in range (0, num_sentences, batch_size):\n","        x_train = train_sentence_embeddings[j: j+batch_size] \n","        y_train = torch.tensor(train_labels[j : j+batch_size])  \n","        x_train = x_train.clone().detach()\n","        y_train = y_train.clone().detach()\n","\n","        x_train = x_train.to(device)\n","        y_train = y_train.to(device)\n","\n","        op = mlp(x_train)\n","\n","        optimizer.zero_grad()\n","        loss = loss_fn(op, y_train)\n","        loss.backward() \n","        optimizer.step()\n","    \n","    if i%1 == 0:\n","        print(\"epoch {} loss : {}\".format(i,loss.item()))\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3210,"status":"aborted","timestamp":1670701641234,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"aJ3qGiSjt-1w"},"outputs":[],"source":["def eval(sentence_embeddings, labels): #evaluation function\n","    hypothesis = []\n","    reference = []\n","    mlp.eval()\n","    for i in range (0, num_sentences, batch_size):\n","        with torch.no_grad():\n","            x_dev = sentence_embeddings[i: i+batch_size]  \n","            y_dev = torch.tensor(labels[i: i+batch_size])  \n","            x_dev = x_dev.clone().detach()\n","            y_dev = y_dev.clone().detach()\n","\n","            x_dev = x_dev.to(device)\n","            y_dev = y_dev.to(device)\n","\n","            op = mlp(x_dev)\n","            y_pred = torch.where(op \u003e= 0.5, 1.0, 0.0)  # simple idea for binary classification ; if probability \u003e=0.5 classify as 1 else as 0\n","            \n","            hypothesis.extend(y_pred.squeeze().tolist())\n","            reference.extend(y_dev.squeeze().tolist())\n","    \n","    return hypothesis, reference"]},{"cell_type":"markdown","metadata":{"id":"WOtM8z7Q1j9r"},"source":["### WinDiff Metric\n","\n","Although we can calculate accuracy to measure how well our predictions match the labels, another very important metric for segmentation tasks is the WinDiff metric. You can learn more about it from this [link](https://www.nltk.org/_modules/nltk/metrics/windowdiff.html)\n","\n","The WinDiff metric will calculate an absolute score, and we use a window size of 3 for our evaluation of this task. Do note, lower the WinDiff score, the better the model."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3209,"status":"aborted","timestamp":1670701641235,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"M4fUAMdhGm31"},"outputs":[],"source":["def winDiff(hypothesis, reference, k):\n","    if len(hypothesis) != len(reference):\n","        raise ValueError(\"Segmentations have unequal length\")\n","    wd = 0\n","    for i in range(len(hypothesis) - k):\n","        wd += abs(hypothesis[i:i+k+1].count(1) - reference[i:i+k+1].count(1))\n","    return wd"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3207,"status":"aborted","timestamp":1670701641235,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"F9dYFfDynUiM"},"outputs":[],"source":["hypothesis, reference = eval(dev_sentence_embeddings, dev_labels)\n","wd = winDiff(hypothesis, reference, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3206,"status":"aborted","timestamp":1670701641235,"user":{"displayName":"GyuSeok Lee","userId":"03967226578516930834"},"user_tz":300},"id":"3ZkyGnPrkwm_"},"outputs":[],"source":["print('WindowDiff:', wd)\n","print(hypothesis)\n","print(reference)"]},{"cell_type":"markdown","metadata":{"id":"E7IU8D9O1n2A"},"source":["# Part 2 (30 points)"]},{"cell_type":"markdown","metadata":{"id":"LliohBkWLiv7"},"source":["### 2.1 What else can you try? (20 points)\n","\n","Our aim this whole assignment was not to burden you with trying to improve a baseline, but rather focus your learning on extracting different features and understand why these features are important in improving model performance. \n","\n","We gave you 4 simple ideas to extract features and a simple MLP model. But there are several limitations in them. Can you try improving this?\n","\n","In this section, we ask you to try **at least two new experiments** with your own ideas for feature extraction or improving the model. You can come up with a new feature altogether, or make some significant changes to the model. Tabulate your scores using these new ideas, and mention them in a report. In the report, we also expect a short description for each of your ideas and why you think it improved or did not improve the results. \n","\n","We can help you with some ideas:\n","\n","\n","\u003e 1. Let's think about the cosine similarity metric. Is it really helpful in capturing the similarity between sentences? Maybe not in this case where we use word indices to obtain word embeddings. Can we use pre-trained word embeddings like [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html)?\n","\u003e 2. We use a simple MLP model. You can add more layers to this model. Or you can even try using an LSTM.\n","\u003e 3. Capturing coreference considers only the immediate previous and next sentence. You can try improving this window. Also do you think passing whole numbers to the model works better, or do you want to try normalizing them?\n","\n","You've learnt a great deal about NLP in this course; use this part of the Homework to be creative and show-off your newly developed NLP skills. **We'd highly appreciate and reward new \u0026 innovative ideas!**\n","\n","**Note**: changes in the hyperparameters alone, such as changing the learning rate or embedding size etc. only, will not be accepted as an experiment. We want your idea to be concrete (and you can specify what hyperparamaters you used).\n","\n","Need help? Feel free to reach out during Office Hours or on Piazza, we will be happy to discuss ideas.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eI72t6Sa02UP"},"source":["### 2.2 Predictions on Test set (10 points)\n","\n","\n","Choose your best model and sentence embedding technique, by looking at results obtained on the val set, and use it to obtain predictions on the test set. \n","\n","The following code should help store hypothesis on the test set to a .txt file as needed in the submission. We will evaluate the WinDiff score obtained by your best model on a threshold set by us. \n","\n","Be sure to use the best model and concatenate the best sentence embedding features in test_sentence_embeddings, and update the hypothesis variable\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_htjmObcjqY"},"outputs":[],"source":["hypothesis, actuals = eval(test_sentence_embeddings, test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIovcfXC01mg"},"outputs":[],"source":["with open(\"/content/drive/MyDrive/HW9/predictions.txt\", \"w\") as output:\n","    output.write(\"\\n\".join(str(item) for item in hypothesis))"]},{"cell_type":"markdown","metadata":{"id":"gKUgD5ArIw2E"},"source":["# **Submission**\n","\n","You are expected to submit:\n","\n","1. **para_seg.py**: copy the required functions or classes from the notebook to the python file given in the handout. We require only the functions and classes mentioned. \n","2. **predictions.txt**: the output predictions file generated on the hidden test case\n","3. **report.pdf**: in a separate written submission, submit your report as specified in Part 2 (2.1). Describe your experiments i.e. why you think it should improve performance, your implementation, and discuss your results"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["F4k4c9SRGl_g"],"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}