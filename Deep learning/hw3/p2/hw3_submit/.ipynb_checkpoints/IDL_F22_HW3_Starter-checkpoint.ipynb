{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR4qfYrVoO4v"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd5aNaLVoR_g"
   },
   "source": [
    "## wandb\n",
    "\n",
    "You will need to fetch your api key from wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mA9qZoIDcx-h"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PiDduMaDIARE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/gyuseok/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"e0408f5d7b96be3d00be30b39eda0f1e259672ed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4s52yBOvICPZ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15663/3624585893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hw3p2-ablations\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m### Project should be created in your wandb account\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;31m### Wandb Config for your run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    name = \"early-submission\", ## Wandb creates random run names if you skip this field\n",
    "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"hw3p2-ablations\", ### Project should be created in your wandb account \n",
    "    config = config ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONgAWhqdoYy-"
   },
   "source": [
    "## Levenshtein\n",
    "\n",
    "This may take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SS7a7xeEoaV9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.20.8-py3-none-any.whl (9.4 kB)\n",
      "Collecting Levenshtein==0.20.8\n",
      "  Downloading Levenshtein-0.20.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (175 kB)\n",
      "\u001b[K     |████████████████████████████████| 175 kB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
      "  Downloading rapidfuzz-2.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.20.8 python-Levenshtein-0.20.8 rapidfuzz-2.13.0\n",
      "Cloning into 'ctcdecode'...\n",
      "remote: Enumerating objects: 1102, done.\u001b[K\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063\u001b[K\n",
      "Receiving objects: 100% (1102/1102), 782.27 KiB | 13.97 MiB/s, done.\n",
      "Resolving deltas: 100% (529/529), done.\n",
      "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
      "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
      "Cloning into '/home/gyuseok/CMU/HW3/ctcdecode/third_party/ThreadPool'...\n",
      "remote: Enumerating objects: 82, done.        \n",
      "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
      "Cloning into '/home/gyuseok/CMU/HW3/ctcdecode/third_party/kenlm'...\n",
      "remote: Enumerating objects: 14102, done.        \n",
      "remote: Counting objects: 100% (415/415), done.        \n",
      "remote: Compressing objects: 100% (289/289), done.        \n",
      "remote: Total 14102 (delta 127), reused 382 (delta 112), pack-reused 13687        \n",
      "Receiving objects: 100% (14102/14102), 5.89 MiB | 5.68 MiB/s, done.\n",
      "Resolving deltas: 100% (8007/8007), done.\n",
      "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
      "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=17a33424f4e2ce28c7f9e87b56021289540e3335dfec9ca3bb6bbab68e9827fd\n",
      "  Stored in directory: /home/gyuseok/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "/home/gyuseok/CMU/HW3/ctcdecode\n",
      "Processing /home/gyuseok/CMU/HW3/ctcdecode\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Building wheels for collected packages: ctcdecode\n",
      "  Building wheel for ctcdecode (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ctcdecode: filename=ctcdecode-1.0.3-cp37-cp37m-linux_x86_64.whl size=13445549 sha256=2d99519a9d8298e87e47365574c53ad34b047e167b8791b6dabf2bfe044f726d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vf_0c5hp/wheels/37/1e/5c/0d8a034e20453808d2436b6512aad269c608ef9e3e4fbbd0ad\n",
      "Successfully built ctcdecode\n",
      "Installing collected packages: ctcdecode\n",
      "Successfully installed ctcdecode-1.0.3\n",
      "/home/gyuseok/CMU/HW3\n",
      "Requirement already satisfied: torchsummaryX in /home/gyuseok/anaconda3/envs/py376/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/gyuseok/anaconda3/envs/py376/lib/python3.7/site-packages (from torchsummaryX) (1.21.5)\n",
      "Requirement already satisfied: torch in /home/gyuseok/anaconda3/envs/py376/lib/python3.7/site-packages (from torchsummaryX) (1.11.0)\n",
      "Requirement already satisfied: pandas in /home/gyuseok/anaconda3/envs/py376/lib/python3.7/site-packages (from torchsummaryX) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/gyuseok/anaconda3/envs/py376/lib/python3.7/site-packages (from pandas->torchsummaryX) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/gyuseok/anaconda3/envs/py376/lib/python3.7/site-packages (from pandas->torchsummaryX) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gyuseok/anaconda3/envs/py376/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.16.0)\n",
      "Requirement already satisfied: typing_extensions in /home/gyuseok/anaconda3/envs/py376/lib/python3.7/site-packages (from torch->torchsummaryX) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein\n",
    "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "!pip install wget\n",
    "%cd ctcdecode\n",
    "!pip install .\n",
    "%cd ..\n",
    "\n",
    "!pip install torchsummaryX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWVONJxCobPc"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78ZTCIXoof2f",
    "outputId": "cf7c8f82-7aab-49ce-a68c-59b38e957cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummaryX import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torchaudio.transforms as tat\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# imports for decoding and distance calculation\n",
    "import ctcdecode\n",
    "import Levenshtein\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg3-yJ8tok34"
   },
   "source": [
    "# Kaggle Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AdUelfGhom1m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle==1.5.8\n",
      "  Using cached kaggle-1.5.8-py3-none-any.whl\n",
      "Installing collected packages: kaggle\n",
      "  Attempting uninstall: kaggle\n",
      "    Found existing installation: kaggle 1.5.8\n",
      "    Uninstalling kaggle-1.5.8:\n",
      "      Successfully uninstalled kaggle-1.5.8\n",
      "Successfully installed kaggle-1.5.8\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
    "#!mkdir /root/.kaggle\n",
    "\n",
    "with open(\"/home/gyuseok/.kaggle/kaggle.json\", \"w+\") as f:\n",
    "    f.write('{\"username\":\"leepro\",\"key\":\"2842f0b3a1e5a14ccddb8ba7fc0a016b\"}') \n",
    "\n",
    "!chmod 600 /home/gyuseok/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSjBwfXeoq4B",
    "outputId": "6515a9e6-3799-4293-d4b7-9e86bd61006c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 11-785-f22-hw3p2.zip to /home/gyuseok/CMU/HW3\n",
      "100%|█████████████████████████████████████▉| 8.89G/8.89G [04:58<00:00, 32.7MB/s]\n",
      "100%|██████████████████████████████████████| 8.89G/8.89G [04:58<00:00, 32.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c 11-785-f22-hw3p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ruxWP60LCQA",
    "outputId": "42a894c0-09fa-4650-8ad2-e75557ec7d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-785-f22-hw3p2.zip  ctcdecode  hw3p2\tIDL_F22_HW3_Starter.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This will take a couple minutes, but you should see at least the following:\n",
    "11-785-f22-hw3p2.zip  ctcdecode  hw3p2\n",
    "'''\n",
    "!unzip -q 11-785-f22-hw3p2.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9v5ewZDMpYA"
   },
   "source": [
    "# Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Cp-716IMZRd",
    "outputId": "ea6dfaa1-32bc-4f57-fde7-07f99056ed18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ORNHnSFroP0"
   },
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k0v7wHRWrqH6"
   },
   "outputs": [],
   "source": [
    "# ARPABET PHONEME MAPPING\n",
    "# DO NOT CHANGE\n",
    "# This overwrites the phonetics.py file.\n",
    "\n",
    "CMUdict_ARPAbet = {\n",
    "    \"\" : \" \", # BLANK TOKEN\n",
    "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\", \n",
    "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\", \n",
    "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\", \n",
    "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\", \n",
    "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\", \n",
    "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\", \n",
    "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\", \n",
    "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
    "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"}\n",
    "\n",
    "CMUdict = list(CMUdict_ARPAbet.keys())\n",
    "ARPAbet = list(CMUdict_ARPAbet.values())\n",
    "\n",
    "\n",
    "PHONEMES = CMUdict\n",
    "mapping = CMUdict_ARPAbet\n",
    "LABELS = ARPAbet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agmNBKf4JrLV"
   },
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "afd0_vlbJmr_"
   },
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    # For this homework, we give you full flexibility to design your data set class.\n",
    "    # Hint: The data from HW1 is very similar to this HW\n",
    "\n",
    "    #TODO\n",
    "    def __init__(self, origin_path): \n",
    "        '''\n",
    "        Initializes the dataset.\n",
    "\n",
    "        INPUTS: What inputs do you need here?\n",
    "        '''\n",
    "\n",
    "        # Load the directory and all files in them\n",
    "        \n",
    "        self.origin_path = origin_path #\"/home/gyuseok/CMU/HW3/hw3p2/train-clean-360\"\n",
    "        \n",
    "        self.mfcc_dir = os.path.join(self.origin_path,\"mfcc\")\n",
    "        self.transcript_dir = os.path.join(self.origin_path, \"transcript\",\"raw\")\n",
    "\n",
    "        self.mfcc_files = sorted(os.listdir(self.mfcc_dir)) #TODO\n",
    "        self.transcript_files = sorted(os.listdir(self.transcript_dir)) #TODO\n",
    "\n",
    "        self.PHONEMES = PHONEMES\n",
    "\n",
    "        #TODO\n",
    "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
    "        self.length = len(self.mfcc_files)\n",
    "        \n",
    "        #TODO\n",
    "        # HOW CAN WE REPRESENT PHONEMES? CAN WE CREATE A MAPPING FOR THEM?\n",
    "        # HINT: TENSORS CANNOT STORE NON-NUMERICAL VALUES OR STRINGS\n",
    "        PHONEMES_dict = {letter:idx for idx,letter in enumerate(self.PHONEMES)}\n",
    "\n",
    "\n",
    "        #TODO\n",
    "        # CREATE AN ARRAY OF ALL FEATUERS AND LABELS\n",
    "        # WHAT NORMALIZATION TECHNIQUE DID YOU USE IN HW1? CAN WE USE IT HERE?\n",
    "        self.mfccs = []\n",
    "        self.transcripts = []\n",
    "        \n",
    "        for i in range(self.length):\n",
    "            mfcc_path = os.path.join(self.mfcc_dir, self.mfcc_files[i])\n",
    "            label_path = os.path.join(self.transcript_dir, self.transcript_files[i])\n",
    "            \n",
    "            mfcc = np.load(mfcc_path)\n",
    "            label = np.load(label_path)\n",
    "            label = np.vectorize(PHONEMES_dict.get)(label) # transform into number\n",
    "            \n",
    "            self.mfccs.append(mfcc)\n",
    "            self.transcripts.append(label)\n",
    "        \n",
    "        '''\n",
    "        You may decide to do this in __getitem__ if you wish.\n",
    "        However, doing this here will make the __init__ function take the load of\n",
    "        loading the data, and shift it away from training.\n",
    "        '''\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        '''\n",
    "        TODO: What do we return here?\n",
    "        '''\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        '''\n",
    "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
    "\n",
    "        If you didn't do the loading and processing of the data in __init__,\n",
    "        do that here.\n",
    "\n",
    "        Once done, return a tuple of features and labels.\n",
    "        '''\n",
    "        mfcc = self.mfccs[ind] # TODO\n",
    "        transcript = self.transcripts[ind] # TODO\n",
    "        \n",
    "        mfcc = torch.FloatTensor(mfcc)\n",
    "        transcript = torch.LongTensor(transcript)\n",
    "        return mfcc, transcript\n",
    "\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        '''\n",
    "        TODO:\n",
    "        1.  Extract the features and labels from 'batch'\n",
    "        2.  We will additionally need to pad both features and labels,\n",
    "            look at pytorch's docs for pad_sequence\n",
    "        3.  This is a good place to perform transforms, if you so wish. \n",
    "            Performing them on batches will speed the process up a bit.\n",
    "        4.  Return batch of features, labels, lenghts of features, \n",
    "            and lengths of labels.\n",
    "        '''\n",
    "        # batch of input mfcc coefficients\n",
    "        batch_mfcc = []\n",
    "        batch_transcript = []\n",
    "        lengths_mfcc = []\n",
    "        lengths_transcript = []\n",
    "        for x,y in batch:\n",
    "            batch_mfcc.append(x) # TODO\n",
    "            batch_transcript.append(y) # TODO\n",
    "            lengths_mfcc.append(x.shape[0])\n",
    "            lengths_transcript.append(y.shape[0])\n",
    "            \n",
    "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
    "        # Also be sure to check the input format (batch_first)\n",
    "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first = True) # TODO\n",
    "        batch_transcript_pad = pad_sequence(batch_transcript, batch_first = True) # TODO\n",
    "\n",
    "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
    "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
    "        #                  -> Would we apply transformation on the validation set as well?\n",
    "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
    "        \n",
    "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
    "        return batch_mfcc_pad, batch_transcript_pad, torch.tensor(lengths_mfcc), torch.tensor(lengths_transcript)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqDrxeHfJw4g"
   },
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HrLS1wfVJppA"
   },
   "outputs": [],
   "source": [
    "# Test Dataloader\n",
    "#TODO\n",
    "class AudioDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, origin_path): \n",
    "        '''\n",
    "        Initializes the dataset.\n",
    "\n",
    "        INPUTS: What inputs do you need here?\n",
    "        '''\n",
    "\n",
    "        # Load the directory and all files in them\n",
    "        self.origin_path = origin_path #\"/home/gyuseok/CMU/HW3/hw3p2/train-clean-360\"\n",
    "        self.mfcc_dir = os.path.join(self.origin_path,\"mfcc\")\n",
    "        self.mfcc_files = sorted(os.listdir(self.mfcc_dir)) #TODO\n",
    "\n",
    "\n",
    "        #TODO\n",
    "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
    "        self.length = len(self.mfcc_files)\n",
    "   \n",
    "        self.mfccs = []        \n",
    "        for i in range(self.length):\n",
    "            mfcc_path = os.path.join(self.mfcc_dir, self.mfcc_files[i])            \n",
    "            mfcc = np.load(mfcc_path)\n",
    "            self.mfccs.append(mfcc)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        mfcc = self.mfccs[ind] # TODO\n",
    "        mfcc = torch.FloatTensor(mfcc)\n",
    "        return mfcc\n",
    "\n",
    "\n",
    "    def collate_fn(self,batch):\n",
    "        '''\n",
    "        TODO:\n",
    "        1.  Extract the features and labels from 'batch'\n",
    "        2.  We will additionally need to pad both features and labels,\n",
    "            look at pytorch's docs for pad_sequence\n",
    "        3.  This is a good place to perform transforms, if you so wish. \n",
    "            Performing them on batches will speed the process up a bit.\n",
    "        4.  Return batch of features, labels, lenghts of features, \n",
    "            and lengths of labels.\n",
    "        '''\n",
    "        # batch of input mfcc coefficients\n",
    "        batch_mfcc = []\n",
    "        lengths_mfcc = []\n",
    "\n",
    "        for x,y in batch:\n",
    "            batch_mfcc.append(x) # TODO\n",
    "            lengths_mfcc.append(x.shape[0])\n",
    "\n",
    "            \n",
    "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
    "        # Also be sure to check the input format (batch_first)\n",
    "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first = True) # TODO\n",
    "\n",
    "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
    "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
    "        #                  -> Would we apply transformation on the validation set as well?\n",
    "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
    "        \n",
    "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
    "        return batch_mfcc_pad, torch.tensor(lengths_mfcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = AudioDataset(\"/home/gyuseok/CMU/HW3/hw3p2/train-clean-100\")\n",
    "val_data = AudioDataset(\"/home/gyuseok/CMU/HW3/hw3p2/dev-clean\")\n",
    "test_data = AudioDatasetTest(\"/home/gyuseok/CMU/HW3/hw3p2/test-clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cepstral Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speechpy\n",
    "import numpy as np\n",
    "\n",
    "def concat_np(data: list):\n",
    "    return np.concatenate(data, axis = 0)\n",
    "\n",
    "def decompose_np(origin_data, target_data):\n",
    "    idxs = [0]\n",
    "    for i in range(len(origin_data)):\n",
    "        length = origin_data.mfccs[i].shape[0]\n",
    "        idxs.append(idxs[i] + length)\n",
    "    idxs = idxs[1:-1]\n",
    "    return np.split(target_data, idxs)\n",
    "    \n",
    "def noramlize_cmvn(train_data, val_data, test_data):\n",
    "    tr, val, te = concat_np(train_data.mfccs), concat_np(val_data.mfccs), concat_np(test_data.mfccs)\n",
    "    total_data = concat_np([tr, val, te])\n",
    "    total_data = speechpy.processing.cmvn(total_data, variance_normalization = True)\n",
    "    \n",
    "    train_idx = tr.shape[0]\n",
    "    test_idx = train_idx + val.shape[0]\n",
    "    \n",
    "    n_train = total_data[:train_idx, :]\n",
    "    n_val = total_data[train_idx:test_idx, :]\n",
    "    n_test = total_data[test_idx:, :]\n",
    "    \n",
    "    train_data.mfccs = decompose_np(train_data, n_train)\n",
    "    val_data.mfccs = decompose_np(val_data, n_val)\n",
    "    test_data.mfccs = decompose_np(test_data, n_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noramlize_cmvn(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pt-veYcdL6Fe"
   },
   "source": [
    "### Data - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4icymeX1ImUN"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 # Increase if your device can handle it\n",
    "\n",
    "transforms = [] # set of tranformations\n",
    "# You may pass this as a parameter to the dataset class above\n",
    "# This will help modularize your implementation\n",
    "\n",
    "root = '/content/hw3p2' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmuPk9J6L8dz"
   },
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_kG0gU2x4hH",
    "outputId": "95a65754-500e-42ba-99c8-7b90bd6e1ff4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get me RAMMM!!!! \n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n",
    "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, \n",
    "                          shuffle = True, drop_last = False, collate_fn = train_data.collate_fn,\n",
    "                          num_workers = 40, pin_memory = True) #TODO\n",
    "\n",
    "val_loader = DataLoader(val_data, batch_size = BATCH_SIZE, \n",
    "                        shuffle = False, drop_last = False, collate_fn = val_data.collate_fn,\n",
    "                        num_workers = 40, pin_memory = True)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size = BATCH_SIZE, \n",
    "                         shuffle = False, drop_last = False, collate_fn = test_data.collate_fn,\n",
    "                         num_workers = 40, pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  64\n",
      "Train dataset samples = 28539, batches = 446\n",
      "Val dataset samples = 2703, batches = 43\n",
      "Test dataset samples = 2620, batches = 41\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch size: \", BATCH_SIZE)\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1654, 15]) torch.Size([64, 198]) torch.Size([64]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "for data in train_loader:\n",
    "    x, y, lx, ly = data\n",
    "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly4mjUUUuJhy"
   },
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZ-qQ_Sf-LIu",
    "outputId": "ad9dc97d-1812-4bd4-cd13-50fed9d9034d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT_SIZE = len(LABELS)\n",
    "OUT_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLad4pChcuvX"
   },
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "EQhvHr71GJfq"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "def DS_block(in_channel, out_channel):\n",
    "    return nn.Sequential(\n",
    "                         nn.Conv1d(in_channel, in_channel, kernel_size = 3, stride = 2, groups = in_channel),\n",
    "                         nn.BatchNorm1d(in_channel),\n",
    "                         nn.ReLU(),\n",
    "        \n",
    "                         nn.Conv1d(in_channel, out_channel, kernel_size = 1, stride = 1),\n",
    "                         nn.BatchNorm1d(out_channel),\n",
    "                         nn.ReLU(),\n",
    "                        )\n",
    "\n",
    "def Res_Block(in_channel, out_channel):\n",
    "    return nn.Sequential(\n",
    "                         nn.Conv1d(in_channel, out_channel, kernel_size = 1, stride = 1),\n",
    "                         nn.BatchNorm1d(out_channel),\n",
    "                         nn.ReLU(),\n",
    "        \n",
    "                         nn.Conv1d(out_channel, in_channel, kernel_size = 1, stride = 1),\n",
    "                         nn.BatchNorm1d(in_channel),\n",
    "                         nn.ReLU(),\n",
    "                        )\n",
    "\n",
    "def make_DS_Res_Block(dims):\n",
    "    ds_dims = dims[:-1]\n",
    "    rs_dims = dims[1:]\n",
    "\n",
    "    ds_layer = []\n",
    "    ds_dims = list(zip(ds_dims[:-1], ds_dims[1:]))\n",
    "    for in_dim, out_dim in ds_dims:\n",
    "        ds_layer += [DS_block(in_dim, out_dim)]\n",
    "\n",
    "    rs_layer = []\n",
    "    rs_dims = list(zip(rs_dims[:-1], rs_dims[1:]))\n",
    "    for in_dim, out_dim in rs_dims:\n",
    "        rs_layer += [Res_Block(in_dim, out_dim)]\n",
    "    \n",
    "    return ds_layer, rs_layer\n",
    "\n",
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, dims = None):\n",
    "\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        # Adding some sort of embedding layer or feature extractor might help performance.\n",
    "        if dims is None:\n",
    "            dims = [15, 1024, 1024, 1024, 512, 512, 512, 512, 256, 256, 256]\n",
    "        \n",
    "        ds_layer, rs_layer = make_DS_Res_Block(dims)\n",
    "        self.ds_layer = nn.ModuleList(ds_layer)\n",
    "        self.rs_layer = nn.ModuleList(rs_layer)\n",
    "\n",
    "        \n",
    "        # TODO : look up the documentation. You might need to pass some additional parameters.\n",
    "        self.lstm1 = nn.LSTM(input_size = 256, hidden_size = 256, num_layers = 2, batch_first = True) \n",
    "        self.lstm2 = nn.LSTM(input_size = 256, hidden_size = 256, num_layers = 2, batch_first = True)\n",
    "        \n",
    "        '''\n",
    "        self.classification = nn.Sequential(\n",
    "            #TODO: Linear layer with in_features from the lstm module above and out_features = OUT_SIZE\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.logSoftmax = #TODO: Apply a log softmax here. Which dimension would apply it on ?\n",
    "        '''\n",
    "        \n",
    "    def forward(self, x, lx):\n",
    "        out = x.permute(0,2,1)\n",
    "        for i in range(len(self.ds_layer)):\n",
    "            out = self.ds_layer[i](out)\n",
    "            out += self.rs_layer[i](out)\n",
    "            \n",
    "        out = out.permute(0,2,1)\n",
    "        out, (hn, cn) = self.lstm1(out)\n",
    "        #out, (hn, cn) = self.lstm2(out)\n",
    "        return out, hn, cn\n",
    "        \n",
    "        \n",
    "        #TODO\n",
    "        # The forward function takes 2 parameter inputs here. Why?\n",
    "        # Refer to the handout for hints\n",
    "        return output, (hn, cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUThsowyQdN7"
   },
   "source": [
    "## INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 208.00 MiB (GPU 0; 11.91 GiB total capacity; 11.06 GiB already allocated; 53.94 MiB free; 11.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51970/340005304.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py376/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_51970/586819555.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lx)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrs_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py376/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py376/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py376/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py376/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py376/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 208.00 MiB (GPU 0; 11.91 GiB total capacity; 11.06 GiB already allocated; 53.94 MiB free; 11.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "output, hn, cn = model(x.to(device), lx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 256])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 256])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CGoiXd70tb5z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================\n",
      "                                 Kernel Shape     Output Shape     Params  \\\n",
      "Layer                                                                       \n",
      "0_ds_layer.0.Conv1d_0              [1, 15, 3]    [64, 15, 826]       60.0   \n",
      "1_ds_layer.0.BatchNorm1d_1               [15]    [64, 15, 826]       30.0   \n",
      "2_ds_layer.0.ReLU_2                         -    [64, 15, 826]          -   \n",
      "3_ds_layer.0.Conv1d_3           [15, 1024, 1]  [64, 1024, 826]    16.384k   \n",
      "4_ds_layer.0.BatchNorm1d_4             [1024]  [64, 1024, 826]     2.048k   \n",
      "5_ds_layer.0.ReLU_5                         -  [64, 1024, 826]          -   \n",
      "6_rs_layer.0.Conv1d_0         [1024, 1024, 1]  [64, 1024, 826]    1.0496M   \n",
      "7_rs_layer.0.BatchNorm1d_1             [1024]  [64, 1024, 826]     2.048k   \n",
      "8_rs_layer.0.ReLU_2                         -  [64, 1024, 826]          -   \n",
      "9_rs_layer.0.Conv1d_3         [1024, 1024, 1]  [64, 1024, 826]    1.0496M   \n",
      "10_rs_layer.0.BatchNorm1d_4            [1024]  [64, 1024, 826]     2.048k   \n",
      "11_rs_layer.0.ReLU_5                        -  [64, 1024, 826]          -   \n",
      "12_ds_layer.1.Conv1d_0           [1, 1024, 3]  [64, 1024, 412]     4.096k   \n",
      "13_ds_layer.1.BatchNorm1d_1            [1024]  [64, 1024, 412]     2.048k   \n",
      "14_ds_layer.1.ReLU_2                        -  [64, 1024, 412]          -   \n",
      "15_ds_layer.1.Conv1d_3        [1024, 1024, 1]  [64, 1024, 412]    1.0496M   \n",
      "16_ds_layer.1.BatchNorm1d_4            [1024]  [64, 1024, 412]     2.048k   \n",
      "17_ds_layer.1.ReLU_5                        -  [64, 1024, 412]          -   \n",
      "18_rs_layer.1.Conv1d_0        [1024, 1024, 1]  [64, 1024, 412]    1.0496M   \n",
      "19_rs_layer.1.BatchNorm1d_1            [1024]  [64, 1024, 412]     2.048k   \n",
      "20_rs_layer.1.ReLU_2                        -  [64, 1024, 412]          -   \n",
      "21_rs_layer.1.Conv1d_3        [1024, 1024, 1]  [64, 1024, 412]    1.0496M   \n",
      "22_rs_layer.1.BatchNorm1d_4            [1024]  [64, 1024, 412]     2.048k   \n",
      "23_rs_layer.1.ReLU_5                        -  [64, 1024, 412]          -   \n",
      "24_ds_layer.2.Conv1d_0           [1, 1024, 3]  [64, 1024, 205]     4.096k   \n",
      "25_ds_layer.2.BatchNorm1d_1            [1024]  [64, 1024, 205]     2.048k   \n",
      "26_ds_layer.2.ReLU_2                        -  [64, 1024, 205]          -   \n",
      "27_ds_layer.2.Conv1d_3        [1024, 1024, 1]  [64, 1024, 205]    1.0496M   \n",
      "28_ds_layer.2.BatchNorm1d_4            [1024]  [64, 1024, 205]     2.048k   \n",
      "29_ds_layer.2.ReLU_5                        -  [64, 1024, 205]          -   \n",
      "30_rs_layer.2.Conv1d_0         [1024, 512, 1]   [64, 512, 205]     524.8k   \n",
      "31_rs_layer.2.BatchNorm1d_1             [512]   [64, 512, 205]     1.024k   \n",
      "32_rs_layer.2.ReLU_2                        -   [64, 512, 205]          -   \n",
      "33_rs_layer.2.Conv1d_3         [512, 1024, 1]  [64, 1024, 205]   525.312k   \n",
      "34_rs_layer.2.BatchNorm1d_4            [1024]  [64, 1024, 205]     2.048k   \n",
      "35_rs_layer.2.ReLU_5                        -  [64, 1024, 205]          -   \n",
      "36_ds_layer.3.Conv1d_0           [1, 1024, 3]  [64, 1024, 102]     4.096k   \n",
      "37_ds_layer.3.BatchNorm1d_1            [1024]  [64, 1024, 102]     2.048k   \n",
      "38_ds_layer.3.ReLU_2                        -  [64, 1024, 102]          -   \n",
      "39_ds_layer.3.Conv1d_3         [1024, 512, 1]   [64, 512, 102]     524.8k   \n",
      "40_ds_layer.3.BatchNorm1d_4             [512]   [64, 512, 102]     1.024k   \n",
      "41_ds_layer.3.ReLU_5                        -   [64, 512, 102]          -   \n",
      "42_rs_layer.3.Conv1d_0          [512, 512, 1]   [64, 512, 102]   262.656k   \n",
      "43_rs_layer.3.BatchNorm1d_1             [512]   [64, 512, 102]     1.024k   \n",
      "44_rs_layer.3.ReLU_2                        -   [64, 512, 102]          -   \n",
      "45_rs_layer.3.Conv1d_3          [512, 512, 1]   [64, 512, 102]   262.656k   \n",
      "46_rs_layer.3.BatchNorm1d_4             [512]   [64, 512, 102]     1.024k   \n",
      "47_rs_layer.3.ReLU_5                        -   [64, 512, 102]          -   \n",
      "48_ds_layer.4.Conv1d_0            [1, 512, 3]    [64, 512, 50]     2.048k   \n",
      "49_ds_layer.4.BatchNorm1d_1             [512]    [64, 512, 50]     1.024k   \n",
      "50_ds_layer.4.ReLU_2                        -    [64, 512, 50]          -   \n",
      "51_ds_layer.4.Conv1d_3          [512, 512, 1]    [64, 512, 50]   262.656k   \n",
      "52_ds_layer.4.BatchNorm1d_4             [512]    [64, 512, 50]     1.024k   \n",
      "53_ds_layer.4.ReLU_5                        -    [64, 512, 50]          -   \n",
      "54_rs_layer.4.Conv1d_0          [512, 512, 1]    [64, 512, 50]   262.656k   \n",
      "55_rs_layer.4.BatchNorm1d_1             [512]    [64, 512, 50]     1.024k   \n",
      "56_rs_layer.4.ReLU_2                        -    [64, 512, 50]          -   \n",
      "57_rs_layer.4.Conv1d_3          [512, 512, 1]    [64, 512, 50]   262.656k   \n",
      "58_rs_layer.4.BatchNorm1d_4             [512]    [64, 512, 50]     1.024k   \n",
      "59_rs_layer.4.ReLU_5                        -    [64, 512, 50]          -   \n",
      "60_ds_layer.5.Conv1d_0            [1, 512, 3]    [64, 512, 24]     2.048k   \n",
      "61_ds_layer.5.BatchNorm1d_1             [512]    [64, 512, 24]     1.024k   \n",
      "62_ds_layer.5.ReLU_2                        -    [64, 512, 24]          -   \n",
      "63_ds_layer.5.Conv1d_3          [512, 512, 1]    [64, 512, 24]   262.656k   \n",
      "64_ds_layer.5.BatchNorm1d_4             [512]    [64, 512, 24]     1.024k   \n",
      "65_ds_layer.5.ReLU_5                        -    [64, 512, 24]          -   \n",
      "66_rs_layer.5.Conv1d_0          [512, 512, 1]    [64, 512, 24]   262.656k   \n",
      "67_rs_layer.5.BatchNorm1d_1             [512]    [64, 512, 24]     1.024k   \n",
      "68_rs_layer.5.ReLU_2                        -    [64, 512, 24]          -   \n",
      "69_rs_layer.5.Conv1d_3          [512, 512, 1]    [64, 512, 24]   262.656k   \n",
      "70_rs_layer.5.BatchNorm1d_4             [512]    [64, 512, 24]     1.024k   \n",
      "71_rs_layer.5.ReLU_5                        -    [64, 512, 24]          -   \n",
      "72_ds_layer.6.Conv1d_0            [1, 512, 3]    [64, 512, 11]     2.048k   \n",
      "73_ds_layer.6.BatchNorm1d_1             [512]    [64, 512, 11]     1.024k   \n",
      "74_ds_layer.6.ReLU_2                        -    [64, 512, 11]          -   \n",
      "75_ds_layer.6.Conv1d_3          [512, 512, 1]    [64, 512, 11]   262.656k   \n",
      "76_ds_layer.6.BatchNorm1d_4             [512]    [64, 512, 11]     1.024k   \n",
      "77_ds_layer.6.ReLU_5                        -    [64, 512, 11]          -   \n",
      "78_rs_layer.6.Conv1d_0          [512, 256, 1]    [64, 256, 11]   131.328k   \n",
      "79_rs_layer.6.BatchNorm1d_1             [256]    [64, 256, 11]      512.0   \n",
      "80_rs_layer.6.ReLU_2                        -    [64, 256, 11]          -   \n",
      "81_rs_layer.6.Conv1d_3          [256, 512, 1]    [64, 512, 11]   131.584k   \n",
      "82_rs_layer.6.BatchNorm1d_4             [512]    [64, 512, 11]     1.024k   \n",
      "83_rs_layer.6.ReLU_5                        -    [64, 512, 11]          -   \n",
      "84_ds_layer.7.Conv1d_0            [1, 512, 3]     [64, 512, 5]     2.048k   \n",
      "85_ds_layer.7.BatchNorm1d_1             [512]     [64, 512, 5]     1.024k   \n",
      "86_ds_layer.7.ReLU_2                        -     [64, 512, 5]          -   \n",
      "87_ds_layer.7.Conv1d_3          [512, 256, 1]     [64, 256, 5]   131.328k   \n",
      "88_ds_layer.7.BatchNorm1d_4             [256]     [64, 256, 5]      512.0   \n",
      "89_ds_layer.7.ReLU_5                        -     [64, 256, 5]          -   \n",
      "90_rs_layer.7.Conv1d_0          [256, 256, 1]     [64, 256, 5]    65.792k   \n",
      "91_rs_layer.7.BatchNorm1d_1             [256]     [64, 256, 5]      512.0   \n",
      "92_rs_layer.7.ReLU_2                        -     [64, 256, 5]          -   \n",
      "93_rs_layer.7.Conv1d_3          [256, 256, 1]     [64, 256, 5]    65.792k   \n",
      "94_rs_layer.7.BatchNorm1d_4             [256]     [64, 256, 5]      512.0   \n",
      "95_rs_layer.7.ReLU_5                        -     [64, 256, 5]          -   \n",
      "96_ds_layer.8.Conv1d_0            [1, 256, 3]     [64, 256, 2]     1.024k   \n",
      "97_ds_layer.8.BatchNorm1d_1             [256]     [64, 256, 2]      512.0   \n",
      "98_ds_layer.8.ReLU_2                        -     [64, 256, 2]          -   \n",
      "99_ds_layer.8.Conv1d_3          [256, 256, 1]     [64, 256, 2]    65.792k   \n",
      "100_ds_layer.8.BatchNorm1d_4            [256]     [64, 256, 2]      512.0   \n",
      "101_ds_layer.8.ReLU_5                       -     [64, 256, 2]          -   \n",
      "102_rs_layer.8.Conv1d_0         [256, 256, 1]     [64, 256, 2]    65.792k   \n",
      "103_rs_layer.8.BatchNorm1d_1            [256]     [64, 256, 2]      512.0   \n",
      "104_rs_layer.8.ReLU_2                       -     [64, 256, 2]          -   \n",
      "105_rs_layer.8.Conv1d_3         [256, 256, 1]     [64, 256, 2]    65.792k   \n",
      "106_rs_layer.8.BatchNorm1d_4            [256]     [64, 256, 2]      512.0   \n",
      "107_rs_layer.8.ReLU_5                       -     [64, 256, 2]          -   \n",
      "108_lstm1                                   -     [64, 2, 256]  1.052672M   \n",
      "\n",
      "                                Mult-Adds  \n",
      "Layer                                      \n",
      "0_ds_layer.0.Conv1d_0              37.17k  \n",
      "1_ds_layer.0.BatchNorm1d_1           15.0  \n",
      "2_ds_layer.0.ReLU_2                     -  \n",
      "3_ds_layer.0.Conv1d_3           12.68736M  \n",
      "4_ds_layer.0.BatchNorm1d_4         1.024k  \n",
      "5_ds_layer.0.ReLU_5                     -  \n",
      "6_rs_layer.0.Conv1d_0         866.123776M  \n",
      "7_rs_layer.0.BatchNorm1d_1         1.024k  \n",
      "8_rs_layer.0.ReLU_2                     -  \n",
      "9_rs_layer.0.Conv1d_3         866.123776M  \n",
      "10_rs_layer.0.BatchNorm1d_4        1.024k  \n",
      "11_rs_layer.0.ReLU_5                    -  \n",
      "12_ds_layer.1.Conv1d_0          1.265664M  \n",
      "13_ds_layer.1.BatchNorm1d_1        1.024k  \n",
      "14_ds_layer.1.ReLU_2                    -  \n",
      "15_ds_layer.1.Conv1d_3        432.013312M  \n",
      "16_ds_layer.1.BatchNorm1d_4        1.024k  \n",
      "17_ds_layer.1.ReLU_5                    -  \n",
      "18_rs_layer.1.Conv1d_0        432.013312M  \n",
      "19_rs_layer.1.BatchNorm1d_1        1.024k  \n",
      "20_rs_layer.1.ReLU_2                    -  \n",
      "21_rs_layer.1.Conv1d_3        432.013312M  \n",
      "22_rs_layer.1.BatchNorm1d_4        1.024k  \n",
      "23_rs_layer.1.ReLU_5                    -  \n",
      "24_ds_layer.2.Conv1d_0            629.76k  \n",
      "25_ds_layer.2.BatchNorm1d_1        1.024k  \n",
      "26_ds_layer.2.ReLU_2                    -  \n",
      "27_ds_layer.2.Conv1d_3         214.95808M  \n",
      "28_ds_layer.2.BatchNorm1d_4        1.024k  \n",
      "29_ds_layer.2.ReLU_5                    -  \n",
      "30_rs_layer.2.Conv1d_0         107.47904M  \n",
      "31_rs_layer.2.BatchNorm1d_1         512.0  \n",
      "32_rs_layer.2.ReLU_2                    -  \n",
      "33_rs_layer.2.Conv1d_3         107.47904M  \n",
      "34_rs_layer.2.BatchNorm1d_4        1.024k  \n",
      "35_rs_layer.2.ReLU_5                    -  \n",
      "36_ds_layer.3.Conv1d_0           313.344k  \n",
      "37_ds_layer.3.BatchNorm1d_1        1.024k  \n",
      "38_ds_layer.3.ReLU_2                    -  \n",
      "39_ds_layer.3.Conv1d_3         53.477376M  \n",
      "40_ds_layer.3.BatchNorm1d_4         512.0  \n",
      "41_ds_layer.3.ReLU_5                    -  \n",
      "42_rs_layer.3.Conv1d_0         26.738688M  \n",
      "43_rs_layer.3.BatchNorm1d_1         512.0  \n",
      "44_rs_layer.3.ReLU_2                    -  \n",
      "45_rs_layer.3.Conv1d_3         26.738688M  \n",
      "46_rs_layer.3.BatchNorm1d_4         512.0  \n",
      "47_rs_layer.3.ReLU_5                    -  \n",
      "48_ds_layer.4.Conv1d_0              76.8k  \n",
      "49_ds_layer.4.BatchNorm1d_1         512.0  \n",
      "50_ds_layer.4.ReLU_2                    -  \n",
      "51_ds_layer.4.Conv1d_3           13.1072M  \n",
      "52_ds_layer.4.BatchNorm1d_4         512.0  \n",
      "53_ds_layer.4.ReLU_5                    -  \n",
      "54_rs_layer.4.Conv1d_0           13.1072M  \n",
      "55_rs_layer.4.BatchNorm1d_1         512.0  \n",
      "56_rs_layer.4.ReLU_2                    -  \n",
      "57_rs_layer.4.Conv1d_3           13.1072M  \n",
      "58_rs_layer.4.BatchNorm1d_4         512.0  \n",
      "59_rs_layer.4.ReLU_5                    -  \n",
      "60_ds_layer.5.Conv1d_0            36.864k  \n",
      "61_ds_layer.5.BatchNorm1d_1         512.0  \n",
      "62_ds_layer.5.ReLU_2                    -  \n",
      "63_ds_layer.5.Conv1d_3          6.291456M  \n",
      "64_ds_layer.5.BatchNorm1d_4         512.0  \n",
      "65_ds_layer.5.ReLU_5                    -  \n",
      "66_rs_layer.5.Conv1d_0          6.291456M  \n",
      "67_rs_layer.5.BatchNorm1d_1         512.0  \n",
      "68_rs_layer.5.ReLU_2                    -  \n",
      "69_rs_layer.5.Conv1d_3          6.291456M  \n",
      "70_rs_layer.5.BatchNorm1d_4         512.0  \n",
      "71_rs_layer.5.ReLU_5                    -  \n",
      "72_ds_layer.6.Conv1d_0            16.896k  \n",
      "73_ds_layer.6.BatchNorm1d_1         512.0  \n",
      "74_ds_layer.6.ReLU_2                    -  \n",
      "75_ds_layer.6.Conv1d_3          2.883584M  \n",
      "76_ds_layer.6.BatchNorm1d_4         512.0  \n",
      "77_ds_layer.6.ReLU_5                    -  \n",
      "78_rs_layer.6.Conv1d_0          1.441792M  \n",
      "79_rs_layer.6.BatchNorm1d_1         256.0  \n",
      "80_rs_layer.6.ReLU_2                    -  \n",
      "81_rs_layer.6.Conv1d_3          1.441792M  \n",
      "82_rs_layer.6.BatchNorm1d_4         512.0  \n",
      "83_rs_layer.6.ReLU_5                    -  \n",
      "84_ds_layer.7.Conv1d_0              7.68k  \n",
      "85_ds_layer.7.BatchNorm1d_1         512.0  \n",
      "86_ds_layer.7.ReLU_2                    -  \n",
      "87_ds_layer.7.Conv1d_3            655.36k  \n",
      "88_ds_layer.7.BatchNorm1d_4         256.0  \n",
      "89_ds_layer.7.ReLU_5                    -  \n",
      "90_rs_layer.7.Conv1d_0            327.68k  \n",
      "91_rs_layer.7.BatchNorm1d_1         256.0  \n",
      "92_rs_layer.7.ReLU_2                    -  \n",
      "93_rs_layer.7.Conv1d_3            327.68k  \n",
      "94_rs_layer.7.BatchNorm1d_4         256.0  \n",
      "95_rs_layer.7.ReLU_5                    -  \n",
      "96_ds_layer.8.Conv1d_0             1.536k  \n",
      "97_ds_layer.8.BatchNorm1d_1         256.0  \n",
      "98_ds_layer.8.ReLU_2                    -  \n",
      "99_ds_layer.8.Conv1d_3           131.072k  \n",
      "100_ds_layer.8.BatchNorm1d_4        256.0  \n",
      "101_ds_layer.8.ReLU_5                   -  \n",
      "102_rs_layer.8.Conv1d_0          131.072k  \n",
      "103_rs_layer.8.BatchNorm1d_1        256.0  \n",
      "104_rs_layer.8.ReLU_2                   -  \n",
      "105_rs_layer.8.Conv1d_3          131.072k  \n",
      "106_rs_layer.8.BatchNorm1d_4        256.0  \n",
      "107_rs_layer.8.ReLU_5                   -  \n",
      "108_lstm1                       1.048576M  \n",
      "--------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params            12.093274M\n",
      "Trainable params        12.093274M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             3.646968641G\n",
      "======================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_ds_layer.0.Conv1d_0</th>\n",
       "      <td>[1, 15, 3]</td>\n",
       "      <td>[64, 15, 826]</td>\n",
       "      <td>60.0</td>\n",
       "      <td>37170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_ds_layer.0.BatchNorm1d_1</th>\n",
       "      <td>[15]</td>\n",
       "      <td>[64, 15, 826]</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_ds_layer.0.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 15, 826]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_ds_layer.0.Conv1d_3</th>\n",
       "      <td>[15, 1024, 1]</td>\n",
       "      <td>[64, 1024, 826]</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>12687360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_ds_layer.0.BatchNorm1d_4</th>\n",
       "      <td>[1024]</td>\n",
       "      <td>[64, 1024, 826]</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104_rs_layer.8.ReLU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 256, 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105_rs_layer.8.Conv1d_3</th>\n",
       "      <td>[256, 256, 1]</td>\n",
       "      <td>[64, 256, 2]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106_rs_layer.8.BatchNorm1d_4</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[64, 256, 2]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107_rs_layer.8.ReLU_5</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 256, 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108_lstm1</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 2, 256]</td>\n",
       "      <td>1052672.0</td>\n",
       "      <td>1048576.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Kernel Shape     Output Shape     Params  \\\n",
       "Layer                                                                     \n",
       "0_ds_layer.0.Conv1d_0            [1, 15, 3]    [64, 15, 826]       60.0   \n",
       "1_ds_layer.0.BatchNorm1d_1             [15]    [64, 15, 826]       30.0   \n",
       "2_ds_layer.0.ReLU_2                       -    [64, 15, 826]        NaN   \n",
       "3_ds_layer.0.Conv1d_3         [15, 1024, 1]  [64, 1024, 826]    16384.0   \n",
       "4_ds_layer.0.BatchNorm1d_4           [1024]  [64, 1024, 826]     2048.0   \n",
       "...                                     ...              ...        ...   \n",
       "104_rs_layer.8.ReLU_2                     -     [64, 256, 2]        NaN   \n",
       "105_rs_layer.8.Conv1d_3       [256, 256, 1]     [64, 256, 2]    65792.0   \n",
       "106_rs_layer.8.BatchNorm1d_4          [256]     [64, 256, 2]      512.0   \n",
       "107_rs_layer.8.ReLU_5                     -     [64, 256, 2]        NaN   \n",
       "108_lstm1                                 -     [64, 2, 256]  1052672.0   \n",
       "\n",
       "                               Mult-Adds  \n",
       "Layer                                     \n",
       "0_ds_layer.0.Conv1d_0            37170.0  \n",
       "1_ds_layer.0.BatchNorm1d_1          15.0  \n",
       "2_ds_layer.0.ReLU_2                  NaN  \n",
       "3_ds_layer.0.Conv1d_3         12687360.0  \n",
       "4_ds_layer.0.BatchNorm1d_4        1024.0  \n",
       "...                                  ...  \n",
       "104_rs_layer.8.ReLU_2                NaN  \n",
       "105_rs_layer.8.Conv1d_3         131072.0  \n",
       "106_rs_layer.8.BatchNorm1d_4       256.0  \n",
       "107_rs_layer.8.ReLU_5                NaN  \n",
       "108_lstm1                      1048576.0  \n",
       "\n",
       "[109 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = Network().to(device)\n",
    "summary(model, x.to(device), lx) # x and lx come from the sanity check above :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBwunYpyugFg"
   },
   "source": [
    "# Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MN82c3KpLup8"
   },
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    \"beam_width\" : 2,\n",
    "    \"lr\" : 2e-3,\n",
    "    \"epochs\" : 50\n",
    "    } # Feel free to add more items here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGoozH2nd6KB"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "\n",
    "criterion = # Define CTC loss as the criterion. How would the losses be reduced?\n",
    "# CTC Loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n",
    "# Refer to the handout for hints\n",
    "\n",
    "optimizer =  torch.optim.AdamW(...) # What goes in here?\n",
    "\n",
    "# Declare the decoder. Use the CTC Beam Decoder to decode phonemes\n",
    "# CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n",
    "decoder = #TODO \n",
    "\n",
    "scheduler = #TODO\n",
    "\n",
    "# Mixed Precision, if you need it\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jmc6_4eWL2Xp"
   },
   "source": [
    "### Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHjnCDddL36E"
   },
   "outputs": [],
   "source": [
    "# Use debug = True to see debug outputs\n",
    "def calculate_levenshtein(h, y, lh, ly, decoder, labels, debug = False):\n",
    "\n",
    "    if debug:\n",
    "        pass\n",
    "        # print(f\"\\n----- IN LEVENSHTEIN -----\\n\")\n",
    "        # Add any other debug statements as you may need\n",
    "        # you may want to use debug in several places in this function\n",
    "        \n",
    "    # TODO: look at docs for CTC.decoder and find out what is returned here\n",
    "    (...) = decoder.decode(h, seq_lens = lh)\n",
    "\n",
    "    batch_size = ___ # TODO\n",
    "    distance = 0 # Initialize the distance to be 0 initially\n",
    "\n",
    "    for i in range(batch_size): \n",
    "        # TODO: Loop through each element in the batch\n",
    "        pass\n",
    "\n",
    "    # distance /= batch_size # TODO: Uncomment this, but think about why we are doing this\n",
    "\n",
    "    raise NotImplemented\n",
    "    # return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnTLL-5gMBrY"
   },
   "outputs": [],
   "source": [
    "# ANOTEHR SANITY CHECK\n",
    "\n",
    "with torch.no_grad():\n",
    "  for i, data in enumerate(train_loader):\n",
    "      \n",
    "      #TODO: \n",
    "      # Follow the following steps, and \n",
    "      # Add some print statements here for sanity checking\n",
    "      \n",
    "      #1. What values are you returning from the collate function\n",
    "      #2. Move the features and target to <DEVICE>\n",
    "      #3. Print the shapes of each to get a fair understanding \n",
    "      #4. Pass the inputs to the model\n",
    "            # Think of the following before you implement:\n",
    "            # 4.1 What will be the input to your model?\n",
    "            # 4.2 What would the model output?\n",
    "            # 4.3 Print the shapes of the output to get a fair understanding \n",
    "\n",
    "      # Calculate loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n",
    "      # Calculating the loss is not straightforward. Check the input format of each parameter\n",
    "      \n",
    "      loss = criterion(...) # What goes in here?\n",
    "      print(f\"loss: {loss}\")\n",
    "\n",
    "      distance = calculate_levenshtein(out, y, out_lengths, ly, decoder, LABELS, debug = False)\n",
    "      print(f\"lev-distance: {distance}\")\n",
    "\n",
    "      break # one iteration is enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fLLj5KIMMOe"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kH0RAbCaMl9a"
   },
   "source": [
    "### Eval function\n",
    "Writing a function to do one round of evaluations will help make your code more modular, you can, however, choose to skip this if you'd like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nqLiAmkMMBc"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "def evaluate(data_loader, model):\n",
    "    \n",
    "    dist = 0\n",
    "    loss = 0\n",
    "    batch_bar = tqdm(total=len(data_loader), dynamic_ncols=True, leave=False, position=0, desc='Val') \n",
    "    # TODO Fill this function out, if you're using it.\n",
    "    \n",
    "    return loss, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpYExu4vT4_g"
   },
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tExvyl1BIdMC"
   },
   "outputs": [],
   "source": [
    "# This is for checkpointing, if you're doing it over multiple sessions\n",
    "\n",
    "last_epoch_completed = 0\n",
    "start = last_epoch_completed\n",
    "end = epochs\n",
    "best_val_dist = float(\"inf\") # if you're restarting from some checkpoint, use what you saw there.\n",
    "dist_freq = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGn17rLw9ChF"
   },
   "source": [
    "Again, writing a train step might help you code be more modular. You may choose to skip this and write the whole thing out in the training loop below if you so wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vH4QStLUjH8"
   },
   "outputs": [],
   "source": [
    "def train_step(train_loader, model, optimizer, criterion, scheduler, scaler):\n",
    "    \n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
    "    train_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        # TODO: Fill this with the help of your sanity check\n",
    "\n",
    "        loss = criterion(...)\n",
    "\n",
    "        # HINT: Are you using mixed precision? \n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            loss = f\"{train_loss/ (i+1):.4f}\",\n",
    "            lr = f\"{optimizer.param_groups[0]['lr']}\"\n",
    "        )\n",
    "\n",
    "        train_loss += loss\n",
    "        batch_bar.update()\n",
    "    \n",
    "    batch_bar.close()\n",
    "    train_loss /= ___ # TODO\n",
    "\n",
    "    return train_loss # And anything else you may wish to get out of this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY69hgxUXhTI"
   },
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JR43E28rM9Ak"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "#TODO: Please complete the training loop\n",
    "\n",
    "for epoch in range(train_config[\"epochs\"]):\n",
    "\n",
    "    # one training step\n",
    "    # one validation step (if you want)\n",
    "\n",
    "    # HINT: Calculating levenshtein distance takes a long time. Do you need to do it every epoch?\n",
    "    # Does the training step even need it? \n",
    "\n",
    "    # Where you have your scheduler.step depends on the scheduler you use.\n",
    "\n",
    "    \n",
    "    # Use the below code to save models\n",
    "    if val_dist < best_val_dist:\n",
    "      #path = os.path.join(root_path, model_directory, 'checkpoint' + '.pth')\n",
    "      print(\"Saving model\")\n",
    "      torch.save({'model_state_dict':model.state_dict(),\n",
    "                  'optimizer_state_dict':optimizer.state_dict(),\n",
    "                  'val_dist': val_dist, \n",
    "                  'epoch': epoch}, './checkpoint.pth')\n",
    "      best_val_dist = val_dist\n",
    "      wandb.save('checkpoint.pth')\n",
    "    \n",
    "\n",
    "    # You may want to log some hyperparameters and results on wandb\n",
    "    wandb.log()\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2H4EEj-sD32"
   },
   "source": [
    "# Generate Predictions and Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2moYJhTWsOG-"
   },
   "outputs": [],
   "source": [
    "#TODO: Make predictions\n",
    "\n",
    "# Follow the steps below:\n",
    "# 1. Create a new object for CTCBeamDecoder with larger (why?) number of beams\n",
    "# 2. Get prediction string by decoding the results of the beam decoder\n",
    "\n",
    "decoder_test = CTCBeamDecoder()\n",
    "\n",
    "def make_output(h, lh, decoder, LABELS):\n",
    "  \n",
    "    beam_results, beam_scores, timesteps, out_seq_len = decoder_test.decode() #TODO: What parameters would the decode function take in?\n",
    "    batch_size = #What is the batch size\n",
    "\n",
    "    dist = 0\n",
    "    preds = []\n",
    "    for i in range(batch_size): # Loop through each element in the batch\n",
    "\n",
    "        h_sliced = #TODO: Obtain the beam results\n",
    "        h_string = #TODO: Convert the beam results to phonemes\n",
    "        preds.append(h_string)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d70dvu_lsMlv"
   },
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# Write a function (predict) to generate predictions and submit the file to Kaggle\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "predictions = predict(test_loader, model, decoder, LABELS)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/content/hw3p2/test-clean/transcript/random_submission.csv')\n",
    "df.label = predictions\n",
    "\n",
    "df.to_csv('submission.csv', index = False)\n",
    "!kaggle competitions submit -c <competition> -f submission.csv -m \"I made it!\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UR4qfYrVoO4v",
    "gg3-yJ8tok34",
    "R9v5ewZDMpYA",
    "Ly4mjUUUuJhy",
    "HLad4pChcuvX",
    "tUThsowyQdN7",
    "IBwunYpyugFg",
    "kH0RAbCaMl9a",
    "qpYExu4vT4_g",
    "MY69hgxUXhTI",
    "M2H4EEj-sD32"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
